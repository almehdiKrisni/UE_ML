{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapport TME1 - Arbres de décision, sélection de modèles\n",
    "\n",
    "Membres du binôme :\n",
    "- KRISNI Almehdi\n",
    "- ARICHANDRA Santhos\n",
    "\n",
    "Dans ce TME, on aborde les aspects essentiels des arbres de décision. Les arbres sont des modèles de classification hiérarchique, en d'autres termes, pour des exemples de la forme **x** = *(x1, x2, ..., xd)*, on associe à chaque noeud de l'arbre un test sur une des dimensions de *xi* de la forme *xi* <= s avec s une valeur réelle. Le test indique le noeud fils devant être sélectionné. La feuille atteinte après l'ensemble des tests est la classe prédite pour un exemple.\n",
    "\n",
    "On cherche à implémenter les fonctions utiles au calcul du partitionnement optimal, soit les fonctions de calcul d'entropie. Toutes les méthodes sont situées dans le fichier *entropie.py* du répertoire TME1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du fichier entropie.py\n",
    "import entropie as ent\n",
    "\n",
    "# Import utilitaires\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "On code la méthode *entropie* permettant à partir d'un vecteur (une liste ou un vecteur numpy), de calculer l'entropie de ce vecteur. Une entropie importante représente un ensemble de données hétérogène tandis qu'une entropie nulle représente un ensemble homogéne, soit composé d'une seule et unique valeur.\n",
    "\n",
    "On réalise quelques tests avec la méthode crée sur des vecteurs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur : [2, 0, 2, 5, 8, 4, 4, 4, 9, 1] \tEntropie : 1.8343719702816235\n",
      "Vecteur : [6, 1, 8, 5, 1, 6, 6, 10, 9, 9] \tEntropie : 1.6957425341696346\n",
      "Vecteur : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \tEntropie : 0.0\n"
     ]
    }
   ],
   "source": [
    "# Tests d'entropie\n",
    "vT1 = [random.randint(0, 10) for _ in range(10)]\n",
    "vT2 = [random.randint(0, 10) for _ in range(10)]\n",
    "vT3 = [1 for _ in range(10)]\n",
    "\n",
    "print(\"Vecteur :\", vT1, \"\\tEntropie :\", ent.entropie(vT1))\n",
    "print(\"Vecteur :\", vT2, \"\\tEntropie :\", ent.entropie(vT2))\n",
    "print(\"Vecteur :\", vT3, \"\\tEntropie :\", ent.entropie(vT3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "On code la méthode *entropie_cond* qui à partir d'une liste de vecteurs, calcule l'homogéinité de la partition obtenue. Il s'agit de la moyenne pondérée des entropies des sous-ensembles obtenus.\n",
    "\n",
    "On réalise un test avec les vecteurs créés à l'étape précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble de vecteurs :\n",
      "[2, 0, 2, 5, 8, 4, 4, 4, 9, 1]\n",
      "[6, 1, 8, 5, 1, 6, 6, 10, 9, 9]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Entropie conditionnelle de la partition : 1.176704834817086\n"
     ]
    }
   ],
   "source": [
    "# Test d'entropie conditionnelle\n",
    "print(\"Ensemble de vecteurs :\", vT1, vT2, vT3, sep=\"\\n\")\n",
    "print(\"\\nEntropie conditionnelle de la partition :\", ent.entropie_cond([vT1, vT2, vT3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Afin de charger un extrait des données de la base imdb, on dispose d'un code fourni par le sujet du TME permettant le chargement d'une zone précise du fichier. On exécute le code afin de conserver en mémoire les données et ne pas avoir à les recharger à chaque utilisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data : tableau (films, features), id2titles : dictionnaire id -> titre,\n",
    "# fields : id feature -> nom\n",
    "[data, id2titles, fields]= pickle.load(open(\"imdb_extrait.pkl\", \"rb\"))\n",
    "# La derniere colonne est le vote\n",
    "datax = data [:,:32]\n",
    "datay = np.array([1 if x [33] > 6.5 else -1 for x in data ])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0882f64853dad4c2959728fd5765a8f4f31953d4de2b55ec484562a906c43e55"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
